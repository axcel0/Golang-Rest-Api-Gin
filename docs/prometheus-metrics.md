# Prometheus Metrics Integration

Production-ready Prometheus metrics for monitoring HTTP API performance, request patterns, and system health.

## Overview

The application exposes a `/metrics` endpoint that provides comprehensive metrics in Prometheus format, enabling real-time monitoring and alerting through Prometheus + Grafana stack.

## Metrics Endpoint

**Endpoint:** `GET /metrics`

**Authentication:** None (public endpoint for scraping)

**Format:** Prometheus text-based exposition format

**Example:**
```bash
curl http://localhost:8080/metrics
```

## Available Metrics

### 1. HTTP Request Total

**Metric:** `http_requests_total`

**Type:** Counter

**Description:** Total number of HTTP requests broken down by method, endpoint, and status code.

**Labels:**
- `method` - HTTP method (GET, POST, PUT, DELETE)
- `endpoint` - Full endpoint path (e.g., `/api/v1/users/me`)
- `status` - HTTP status code (200, 201, 400, 401, 500)

**Example Output:**
```
http_requests_total{endpoint="/api/v1/auth/login",method="POST",status="200"} 1
http_requests_total{endpoint="/api/v1/users/me",method="GET",status="200"} 1
http_requests_total{endpoint="/health",method="GET",status="200"} 1
```

**Usage:**
```promql
# Total requests per endpoint
sum(http_requests_total) by (endpoint)

# Error rate (4xx + 5xx)
sum(rate(http_requests_total{status=~"4..|5.."}[5m])) by (endpoint)

# Success rate
sum(rate(http_requests_total{status=~"2.."}[5m])) 
  / sum(rate(http_requests_total[5m]))
```

---

### 2. HTTP Request Duration

**Metric:** `http_request_duration_seconds`

**Type:** Histogram

**Description:** Duration of HTTP requests in seconds with predefined buckets.

**Labels:**
- `method` - HTTP method
- `endpoint` - Full endpoint path
- `status` - HTTP status code

**Buckets:** [0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10]

**Example Output:**
```
http_request_duration_seconds_bucket{endpoint="/api/v1/users/me",method="GET",status="200",le="0.005"} 1
http_request_duration_seconds_sum{endpoint="/api/v1/users/me",method="GET",status="200"} 0.001009927
http_request_duration_seconds_count{endpoint="/api/v1/users/me",method="GET",status="200"} 1
```

**Usage:**
```promql
# Average request duration
rate(http_request_duration_seconds_sum[5m]) 
  / rate(http_request_duration_seconds_count[5m])

# 95th percentile latency
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
)

# Slow requests (>1 second)
sum(rate(http_request_duration_seconds_bucket{le="1"}[5m])) by (endpoint)
```

**Interpretation:**
- Health check: ~0.09ms (very fast)
- GET /users/me: ~1ms (fast DB query)
- PUT /users/me: ~14.7ms (DB write operation)
- POST /auth/register: ~164ms (password hashing + DB write)
- POST /auth/login: ~159ms (password verification + token generation)

---

### 3. HTTP Request Size

**Metric:** `http_request_size_bytes`

**Type:** Summary

**Description:** Size of HTTP request in bytes (headers + body).

**Labels:**
- `method` - HTTP method
- `endpoint` - Full endpoint path

**Example Output:**
```
http_request_size_bytes_sum{endpoint="/api/v1/auth/register",method="POST"} 229
http_request_size_bytes_count{endpoint="/api/v1/auth/register",method="POST"} 1
```

**Usage:**
```promql
# Average request size
http_request_size_bytes_sum / http_request_size_bytes_count

# Total bandwidth received
sum(rate(http_request_size_bytes_sum[5m]))
```

---

### 4. HTTP Response Size

**Metric:** `http_response_size_bytes`

**Type:** Summary

**Description:** Size of HTTP response in bytes.

**Labels:**
- `method` - HTTP method
- `endpoint` - Full endpoint path

**Example Output:**
```
http_response_size_bytes_sum{endpoint="/api/v1/auth/login",method="POST"} 786
http_response_size_bytes_count{endpoint="/api/v1/auth/login",method="POST"} 1
```

**Usage:**
```promql
# Average response size
http_response_size_bytes_sum / http_response_size_bytes_count

# Total bandwidth sent
sum(rate(http_response_size_bytes_sum[5m]))
```

---

### 5. Active Connections

**Metric:** `http_active_connections`

**Type:** Gauge

**Description:** Number of HTTP requests currently being processed.

**Example Output:**
```
http_active_connections 1
```

**Usage:**
```promql
# Current active connections
http_active_connections

# Max concurrent connections in last 5 minutes
max_over_time(http_active_connections[5m])
```

---

### 6. Go Runtime Metrics

Prometheus client automatically exports standard Go runtime metrics:

- `go_goroutines` - Number of active goroutines
- `go_memstats_alloc_bytes` - Bytes of allocated heap objects
- `go_memstats_heap_inuse_bytes` - Bytes in in-use spans
- `go_gc_duration_seconds` - GC pause duration
- `process_cpu_seconds_total` - Total user and system CPU time
- `process_resident_memory_bytes` - Resident memory size

**Usage:**
```promql
# Memory usage
go_memstats_alloc_bytes

# Goroutine count
go_goroutines

# GC frequency
rate(go_gc_duration_seconds_count[5m])
```

---

## Implementation Details

### Metrics Package

Location: `internal/metrics/metrics.go`

**Key Components:**

1. **Metrics Struct** - Holds all Prometheus collectors
   ```go
   type Metrics struct {
       HTTPRequestsTotal   *prometheus.CounterVec
       HTTPRequestDuration *prometheus.HistogramVec
       HTTPRequestSize     *prometheus.SummaryVec
       HTTPResponseSize    *prometheus.SummaryVec
       ActiveConnections   prometheus.Gauge
   }
   ```

2. **NewMetrics()** - Initializes and registers metrics
   - Uses `promauto` for automatic registration
   - Configures histogram buckets for latency
   - Sets up label dimensions

3. **Middleware()** - Gin middleware for automatic instrumentation
   - Tracks active connections (increment on start, decrement on finish)
   - Measures request duration with high precision
   - Computes request/response sizes
   - Records metrics with proper labels

### Integration

Integrated into `cmd/api/main.go`:

```go
// Initialize metrics
prometheusMetrics := metrics.NewMetrics()

// Add middleware (order matters!)
r.Use(middleware.Recovery())        // First: panic recovery
r.Use(middleware.Logger())          // Second: request logging
r.Use(middleware.CORS())            // Third: CORS headers
r.Use(prometheusMetrics.Middleware()) // Fourth: metrics collection
r.Use(middleware.ErrorHandler())    // Last: error handling

// Mount metrics endpoint
r.GET("/metrics", gin.WrapH(promhttp.Handler()))
```

**Important:** Metrics middleware is placed AFTER logging but BEFORE error handling to capture all requests accurately.

---

## Prometheus Configuration

### prometheus.yml

```yaml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'go-rest-api'
    static_configs:
      - targets: ['localhost:8080']
    metrics_path: '/metrics'
    scrape_interval: 10s
```

### Start Prometheus

```bash
# Using Docker
docker run -d \
  --name prometheus \
  -p 9090:9090 \
  -v $(pwd)/prometheus.yml:/etc/prometheus/prometheus.yml \
  prom/prometheus

# Access Prometheus UI
open http://localhost:9090
```

---

## Grafana Dashboard

### Sample Queries

**Request Rate Panel:**
```promql
sum(rate(http_requests_total[5m])) by (endpoint)
```

**Latency Panel (95th percentile):**
```promql
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
)
```

**Error Rate Panel:**
```promql
sum(rate(http_requests_total{status=~"5.."}[5m])) 
  / sum(rate(http_requests_total[5m])) * 100
```

**Active Connections Panel:**
```promql
http_active_connections
```

**Memory Usage Panel:**
```promql
go_memstats_alloc_bytes / 1024 / 1024
```

### Import Dashboard

1. Create Grafana dashboard
2. Add Prometheus data source (http://localhost:9090)
3. Import dashboard JSON or create panels with above queries
4. Set refresh interval to 10s

---

## Alerting Rules

### High Error Rate

```yaml
- alert: HighErrorRate
  expr: |
    sum(rate(http_requests_total{status=~"5.."}[5m])) 
      / sum(rate(http_requests_total[5m])) > 0.05
  for: 5m
  labels:
    severity: critical
  annotations:
    summary: "High error rate detected"
    description: "Error rate is {{ $value | humanizePercentage }}"
```

### High Latency

```yaml
- alert: HighLatency
  expr: |
    histogram_quantile(0.95,
      sum(rate(http_request_duration_seconds_bucket[5m])) by (le, endpoint)
    ) > 1
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "High latency on {{ $labels.endpoint }}"
    description: "95th percentile latency is {{ $value }}s"
```

### High Memory Usage

```yaml
- alert: HighMemoryUsage
  expr: go_memstats_alloc_bytes > 500 * 1024 * 1024
  for: 5m
  labels:
    severity: warning
  annotations:
    summary: "High memory usage"
    description: "Memory usage is {{ $value | humanize }}B"
```

---

## Testing Metrics

### Manual Testing

```bash
# 1. Generate traffic
curl http://localhost:8080/health
curl -X POST http://localhost:8080/api/v1/auth/register \
  -H "Content-Type: application/json" \
  -d '{"name":"Test","email":"test@example.com","password":"pass123","age":25}'

# 2. Check metrics
curl http://localhost:8080/metrics | grep http_requests_total

# 3. View specific metric
curl -s http://localhost:8080/metrics | grep -A 5 "http_request_duration_seconds"
```

### Load Testing

```bash
# Using Apache Bench
ab -n 1000 -c 10 http://localhost:8080/health

# Using wrk
wrk -t4 -c100 -d30s http://localhost:8080/health

# Check metrics after load test
curl http://localhost:8080/metrics | grep http_requests_total
```

---

## Performance Considerations

### Overhead

- **CPU:** ~0.1-0.5% overhead per request (negligible)
- **Memory:** ~10MB for metric storage (grows with cardinality)
- **Latency:** <1Âµs added to request processing time

### Cardinality Management

**Label Best Practices:**
- âœ… Use low-cardinality labels (method, endpoint, status)
- âŒ Avoid high-cardinality labels (user_id, request_id, timestamps)
- âœ… Current setup: ~50-100 unique label combinations
- âš ï¸ Limit: Keep total series below 10,000

**Current Cardinality:**
- Methods: 4 (GET, POST, PUT, DELETE)
- Endpoints: ~15 unique paths
- Status codes: ~10 (200, 201, 400, 401, 403, 404, 500)
- **Total series:** ~600 (4 Ã— 15 Ã— 10)

---

## Troubleshooting

### Metrics Not Updating

```bash
# Check if middleware is registered
grep "prometheusMetrics.Middleware()" cmd/api/main.go

# Verify endpoint accessible
curl http://localhost:8080/metrics
```

### High Memory Usage

```bash
# Check metric cardinality
curl -s http://localhost:8080/metrics | grep -c "http_requests_total"

# If too high, reduce label dimensions
```

### Prometheus Not Scraping

```bash
# Check Prometheus targets
open http://localhost:9090/targets

# Verify endpoint from Prometheus server
docker exec prometheus wget -qO- http://host.docker.internal:8080/metrics
```

---

## Next Steps

After implementing Prometheus metrics, consider:

1. **Enhanced Health Checks** - Add component health (DB, disk, memory)
2. **Custom Business Metrics** - Track user registrations, logins, profile updates
3. **SLO/SLI Definitions** - Define service level objectives
4. **Alerting** - Set up critical alerts (error rate, latency, uptime)
5. **Grafana Dashboard** - Create comprehensive monitoring dashboard

---

## Summary

âœ… **Implemented:**
- Prometheus client library integrated
- HTTP metrics middleware for automatic instrumentation
- 5 custom metrics + Go runtime metrics
- `/metrics` endpoint exposed
- Tested with real traffic
- Production-ready configuration

ðŸ“Š **Metrics Captured:**
- Request count by endpoint/method/status
- Request duration histogram with 11 buckets
- Request/response sizes
- Active connections gauge
- Go runtime metrics (memory, GC, goroutines)

ðŸŽ¯ **Ready for:**
- Prometheus scraping (every 10-15s)
- Grafana visualization
- Alert rule configuration
- SLO/SLI monitoring
- Production observability

**Status:** âœ… COMPLETE - Prometheus metrics fully integrated and tested
**Date:** 2025-10-31
**Version:** 1.0.0
